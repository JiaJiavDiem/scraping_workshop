{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic information Netherlands\n",
    "The intention of this Python script is to scrape actual travel information about expected delays.\n",
    "The first part will do this for traffic, the second part can do this for trains.\n",
    "\n",
    "Source: https://www.anwb.nl/feeds/gethf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages into memory\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from tinydb import TinyDB\n",
    "\n",
    "dbname='traffic_db.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run scraper of data independently\n",
    "```python collect.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve collected raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the current VAT rate in the EU\n",
    "dbname='traffic_db.json'\n",
    "db = TinyDB(dbname)\n",
    "\n",
    "all_data = db.all()\n",
    "\n",
    "# Pandas version 0.25 contains new parameter max_level in json_normalize.\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate JSON data into dataframe (separate parsing from data collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data = pd.DataFrame()\n",
    "\n",
    "for jso in all_data:# Create json object from returned text\n",
    "    #jso = json.loads(routeInfo.text)\n",
    "    # Create dataframe from json object roadEntries\n",
    "    trafficdf = json_normalize(jso['roadEntries'])\n",
    "\n",
    "    # Drop unnecessary columns (I did not find any documentation about the webservice yet to only retrieve what I need.)\n",
    "    trafficdf.drop(columns = ['events.roadWorks','events.radars'],inplace=True)\n",
    "\n",
    "    # Read the number of trafficJams and filter the dataframe on it.\n",
    "    trafficdf['listlength'] = trafficdf['events.trafficJams'].apply(lambda x : len(x))\n",
    "    trafficdf = trafficdf[trafficdf['listlength'] > 0]\n",
    "    trafficdf.drop(columns = ['listlength'], inplace=True)\n",
    "    trafficdf['timestap'] = datetime.now()\n",
    "\n",
    "    # Pop all trafficjams, normalize and join back to dataframe to keep road info.\n",
    "    trafficdf = (pd.concat({i: json_normalize(x) for i, x in trafficdf.pop('events.trafficJams').items()}, sort=True)\n",
    "             .reset_index(level=1, drop=True)\n",
    "             .join(trafficdf)\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "    # Drop all items where no delays are mentioned.\n",
    "    trafficdf = trafficdf.dropna()\n",
    "    trafficdf.drop(columns=['events'],inplace=True)\n",
    "\n",
    "    # Set index to msgNr.\n",
    "    #trafficdf.set_index('msgNr', inplace=True)\n",
    "    traffic_data=traffic_data.append(trafficdf)\n",
    "    #trafficdf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look at trafficinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traffic_data.count())\n",
    "\n",
    "traffic_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latestTimestamp = traffic_data.timestap.max()\n",
    "#dftest[dftest['timestap']==latestTimestamp].plot(x='start',y='delay')\n",
    "#dftest.plot(x='timestap',y='delay')\n",
    "traffic_data['delayMinutes'] = traffic_data['delay'] / 60\n",
    "bp = sns.barplot(x='road',y='delayMinutes',data=traffic_data[traffic_data['timestap']==latestTimestamp])\n",
    "#bp.set_xticklabels(bp.get_xticklabels(), rotation=90)\n",
    "bp.set_title('Actual Delays')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push dataframe to Azure SQL, based on index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params = 'DRIVER={SQL Server};' \\\n",
    "         'SERVER=****;' \\\n",
    "         'PORT=1433;' \\\n",
    "         'DATABASE=o365data;' \\\n",
    "         'UID=****;' \\\n",
    "         'PWD=****;'\n",
    "            \n",
    "params = urllib.parse.quote_plus(params)\n",
    "\n",
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%time trafficdf.to_sql(name='TrafficInformation',con=engine , schema='dbo', if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
